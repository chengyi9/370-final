{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithms</th>\n",
       "      <th>weekday_drinking_accuracy</th>\n",
       "      <th>weekend_drinking_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.580952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Reg</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      algorithms  weekday_drinking_accuracy  weekend_drinking_accuracy\n",
       "0  Decision Tree                   0.666667                   0.542857\n",
       "1  Random Forest                   0.800000                   0.761905\n",
       "2            SVM                   0.628571                   0.580952\n",
       "3   Logistic Reg                   0.660000                   0.470000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "accuracy_df = pd.read_csv(\"accuracy_df.csv\")\n",
    "\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used machine learning approaches to predict the level of students' alcohol consumption on Weekdays and on Weekends using other features that reflect students' family, social, and academic environments. Since we are trying to predict categorical variables (level of students' alcohol consumption from 1 to 5 with 1 being very low and 5 being very high); we decided to use decision tree classifier, random forest classifier, and support vector classifier as our primary machine learning algorithms with multi-class logistic regression as a benchmark for comparison. We believe that decision tree based algorithms like decision tree classifier & random forests  classifier are best suited for this type of classification problem since a significant portion of our independent/expanatory variables are categorical in nature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare our dataset for machine learning algorithms, we first verified that there are no missing values in the dataframe using pandas library's 'isnull()' function. Then, we converted all the categorical dependent variables into binary dummie variables using the 'get_dummies()' function (since all of the categorical features contain fewer than 20 unique values). In addition, we included normalization using 'MinMaxScaler' as part of the pipeline and used the 'sklearn.preprocessing' package's 'train_test_split()' function to split our data into training and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict student alcohol consumption on weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs below represents actual level of alcohol consumption versus predicted level of alcohol consumption on Weekdays. We can clearly see that most data points are clustered around the lower left corner and that our machine learning models performed relatively well on predicting lower levels of alcohol consumptions. In particular, the random forests classifer model yielded the best results with most data points on the 45 degree line (actual = predicted). Furthermore, we discovered that a single decision tree by itself is relatively unstable and inaccurate. On the other hand, the logistic regression (benchmark) performed on par with decision tree classifier and support vector classifier.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classification | Random Forest Classification | Support Vector Classification | Logistic Regression (Benchmark)\n",
    "---- | ---- | ---- | ----\n",
    "![Using decision tree to predict weekday alcohol consumption](img/decision_tree_weekday.png) | ![Using random forest to predict weekday alcohol consumption](img/random_forest_weekday.png) | ![Using SVC to predict weekday alcohol consumption](img/svc_weekday.png) | ![Using logistic regression to predict weekday alcohol consumption](img/logistic_regression_weekday.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict student alcohol consumption on weekends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs below represents actual level of alcohol consumption versus predicted level of alcohol consumption on Weekends. Unlike the previous actual v.s. prediction graph for Weekday alcohol consumption levels, the data points in the graphs below are spread out more evenly across the diagonal line meaning that the overall levels of students' alcohol consumption are higher on Weekends compare to Weekdays. In addition, we discovered that the random forests classifier consistently out performs the benchmark and the other machine learning classifiers. While decision tree classifier, and the support vector classifer performed similarly with almost the same amount of data points on the 45 degree line (actual = predicted). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classification | Random Forest Classification | Support Vector Classification | Logistic Regression (Benchmark)\n",
    "---- | ---- | ---- | ----\n",
    "![Using decision tree to predict weekend alcohol consumption](img/decision_tree_weekend.png) | ![Using random forest to predict weekend alcohol consumption](img/random_forest_weekend.png) | ![Using SVC to predict weekend alcohol consumption](img/svc_weekend.png) | ![Using logistic regression to predict weekend alcohol consumption](img/logistic_regression_weekend.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Graphviz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
